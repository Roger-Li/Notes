{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Looking at a Big Picture\n",
    "### Performance Measure\n",
    "\n",
    "* RMSE Vs MAE\n",
    "    * RMSE$(\\mathbf{X},h)=\\sqrt{\\frac{1}{m}\\sum_{i=1}^{m}(h(\\mathbf{x}^{(i)})-y({(i)})^2}$, $l_2$ norm\n",
    "    * MAE$(\\mathbf{X},h)=\\frac{1}{m}\\sum_{i=1}^{m}\\lvert h(\\mathbf{x}^{(i)})-y{(i)}\\rvert$, $l_1$ norm\n",
    "    * The higher the norm index, the more it focuses on large values and neglects small ones. This is why the RMSE is more sensitive to outliers than MAE. But when outliers are exponentially rare, the RMSE performs very well and is generally preferred.\n",
    "    \n",
    "    \n",
    "Read this! [机器学习模型评估](https://zhuanlan.zhihu.com/p/30721429机器学习模型评估)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data\n",
    "* Useful pandas functions\n",
    "    * `df.info()` `value_counts()`\n",
    "    * `df.hist()`\n",
    "### Create a TestSet\n",
    "* `from sklearn.model_selection import train_test_split`\n",
    "* `from sklearn.model_selection import StratifiedShuffleSplit`\n",
    "\n",
    "## Discover and Visualize the Data to Gain Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data for ML Algorithms\n",
    "### Data Cleaning\n",
    "* Missing value\n",
    "```\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(strategy=\"median\")\n",
    "```\n",
    "`stragegy` could also be `\"mean\"` or `\"most_frequent\"`\n",
    "\n",
    "### Text and Categorical Attributes\n",
    "* **sklearn.preprocessing.LabelEncoder** convert text labels to numbers\n",
    "* **sklearn.preprocessing.OneHotEncoder** convert integer categorical values into one-hot vectors, stored as SciPy sparse matrix by default.\n",
    "* **sklearn.preprocessing.LabelBinarizer** apply both transformations in one shot. Setting *sparse_output=True* get a sparse matrix\n",
    "\n",
    "### Custom Transformers\n",
    "The more cominations youu can automatically try out, the more likely you will find a great feature combination easily.\n",
    "\n",
    "```\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,...)\n",
    "        ...\n",
    "    def fit(self,...)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        ...\n",
    "```\n",
    "\n",
    "### Feature scaling\n",
    "* Standardization Vs Min-Max Scaling: Standardization is less affected by outliers.\n",
    "\n",
    "### Transformation pipelines\n",
    "* `from sklearn.pipline import Pipeline\n",
    "  from sklearn.pipline import ReatureUnion`\n",
    "* Use `'selector'` to transform partial features, and `FeatureUnion()` to combine numerical and categorical feature pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and Train a Model\n",
    "### Better Evaluation Using Cross-Validation\n",
    "* `from sklearn.model_selection import cross_val_score\n",
    "   scores = cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\",cv=10)`\n",
    "* Save all the models/predictions/scores\n",
    "```\n",
    "from sklearn.externals import joblib\n",
    "joblib.dumpy(my_model, \"my_model.pkl\")\n",
    "# and later...\n",
    "my_model_loaded = joblib.load(\"my_model.pkl\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune Your Model\n",
    "### Grid Search\n",
    "* `from sklearn.model_selectionimport GridSearchCV`\n",
    "* Some of the data preparation steps can be treated as hyperparameters using the `CombinedAttributesAdder` transformer.\n",
    "\n",
    "### Randomized Search\n",
    "\n",
    "### Ensemble methods\n",
    "\n",
    "* Top feature selection could also be integrated into data preparation pipeline using `TopFeatureSelector(feature_importances, k)` in a Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch, Monitor, and Maintain Your System\n",
    "\n",
    "Bring human expertise. Check data quality regularly, as could be reflected in the model performance much later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "* Detailed implementation [notebook](https://github.com/ageron/handson-ml/blob/master/02_end_to_end_machine_learning_project.ipynb) by [Aurélien Geron](https://github.com/ageron)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
