{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measures\n",
    "\n",
    "### Measuring Accuracy Using Cross-Validation\n",
    "* Create clone classifer for each CV fold: `from sklearn.base import clone ... clone_clf = clone(sgd_clf)`\n",
    "\n",
    "### Confusion Matrix\n",
    "* the `confusion_matrix` in `sklearn` prints the negative class result in first row, and positive class result in 2nd row.\n",
    "[[TN, FP],[FN, TP]]\n",
    "\n",
    "```\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_train_pred = cross_val_predict(clf, X_train, y_train, cv=3)\n",
    "confusion_matrix(y_train, y_train_pred)\n",
    "```\n",
    "* For multi-class, rows represent actual classes, while columns represent predicted classes.\n",
    "\n",
    "### Precision and Recall \n",
    "* `from sklearn.metrics import precision_score, recall_score, f1_score`\n",
    "* precision = $\\dfrac{TP}{TP+FP}$\n",
    "* recall = $\\dfrac{TP}{TP+FN}$\n",
    "* F1 score (harmonic mean of precision and recall). It favors classifiers that have similar precision and recall.\n",
    "\n",
    "$$F_1 = \\dfrac{2}{\\frac{1}{precision}+\\frac{1}{recall}} = 2\\times \\dfrac{precision\\times recall}{precision+recall}$$\n",
    "\n",
    "### Precision-Recall Tradeoff\n",
    "```\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train, y_scores)\n",
    "```\n",
    "\n",
    "### ROC Curve\n",
    "* plot *true positive rate (recall)* Vs *false positive rate (=FP/(FP+TN))*, in other words, it plots *sensitivity* versus *1-specificity*\n",
    "* <span style=\"color:blue\"> *pp. 91* </span>\n",
    "\n",
    "    ```\n",
    "    from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, y_scores)\n",
    "    roc_auc_score(y_train, y_scores)\n",
    "```\n",
    "\n",
    "* for these plots, we need the `y_score`, which can be obtained from either `decision_function()` or `predict_prob()`\n",
    "\n",
    "* <span style=\"color:blue\"> *pp.88, 92*</span>\n",
    "\n",
    "    ```\n",
    "    y_scores = cross_val_predict(clf, X_train, y_train, cv=3, method = \"decision_function\")\n",
    "    ```\n",
    "\n",
    "    OR\n",
    "\n",
    "    ```\n",
    "    y_probas = cross_val_predict(clf, X_train, y_train, cv=3, method = \"predict_proba\")\n",
    "    y_scores = y_probas[:,1]  # score = proba of positive class\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Classification\n",
    "* Some algorithms (Random Forest, Naive Bayes) are capable of handling multi-class tasks directly, others (SVM, Linear Classifiers) are strictly binary.\n",
    "* For $N$ classes, *one-versus-all* strategy requires $N$ classifiers, *one-versus-one* (distinguish every pair of potential classes) requires $N(N-1)/2$ classifiers.\n",
    "    * For a new instance, run all the `clfs` and select the class with the highest score.\n",
    "    * The **advantage** of OvO is that each `clf` only needs to be trained on the part of the training set for the two classes that it must distinguish. For algorithms that do not scale well (e.g., SVM), OvO is preferred.\n",
    "    * For most binary clf algorithms, OvA is preferred.\n",
    "* Scikit-Learn detects the issue and automatically runs OvA. To use OvO\n",
    "    \n",
    "    ```\n",
    "    from sklearn.multiclass import OneVsOneClassifier\n",
    "    \n",
    "    clf = ...\n",
    "    ovo_clf = OneVsOneClassifier(clf)\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "* Image representation of confusion matrix `plt.matshow(conf_mx, cmap=plt.cm.gray)`\n",
    "* Plot the *error matrix*, fill the diagonals with zeros.\n",
    "    ```\n",
    "    row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "    norm_conf_mx = conf_mx / row_sums\n",
    "    np.fill_diagonal(norm_conf_mx, 0)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel Classification\n",
    "## Multioutput Classification\n",
    "\n",
    "## Exercise\n",
    "* The [notebook] (https://github.com/ageron/handson-ml/blob/master/03_classification.ipynb) contains an implementation of the *Titanic* Kaggle project (Exercises 2). It is a good example for using `Pipeline`, `FeatureUnion`, `Imputer`, etc\n",
    "* **Exercise 2** builds a spam classifier, a good place to learn basic text mining/feature transformation, nltk, etc. How to build a feature transformer class to convert emails to word counters and vectors.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "* Detailed implementation [notebook](https://github.com/ageron/handson-ml/blob/master/03_classification.ipynb) by [Aur√©lien Geron](https://github.com/ageron)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
