{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "* Cost function $MSE(\\mathbf{X},h_\\theta) = \\frac{1}{m}\\sum_{i=1}^m (\\theta^T\\cdot \\mathbf{x}^{(i)}-y^{(i)})^2$\n",
    "* Normal Equation $\\hat{\\theta} = (\\mathbf{X}^T\\cdot \\mathbf{X})^{-1}\\cdot \\mathbf{X}^T \\cdot \\mathbf{y}$, note that $\\mathbf{X}^T\\cdot \\mathbf{X}$ is $n\\times n$, *complexity* of matrix inverse is $O(n^{2.4})$ to $O(n^3)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "### Batch Gradient Descent\n",
    "* *Partial derivatives* $\\dfrac{\\partial}{\\partial \\theta_j} MSE(\\theta) = \\dfrac{2}{m} \\sum_{i=1}^m(\\theta^T\\cdot \\mathbf{x}^{(i)}-y^{(i)})x_j^{(i)}$, and\n",
    "* Gradient vector $\\bigtriangledown_\\theta MSE(\\theta) = [\\dfrac{\\partial}{\\partial \\theta_0} MSE(\\theta), ..., \\dfrac{\\partial}{\\partial \\theta_n} MSE(\\theta) ]^T$\n",
    "* Gradient Descent step $\\theta^{(i+1)} = \\theta^{(i)}-\\eta \\cdot \\bigtriangledown_\\theta MSE(\\theta)$\n",
    "* **Convergence Rate** $O(\\dfrac{1}{\\text{iterations}})$. i.e., 10 times accuracy (divide $\\epsilon$ by 10) leads to 10 times more iterations\n",
    "\n",
    "### Stochastic Gradient Descent\n",
    "* SGD applies one training point at a time, and uses a *learning schedule* to reduce learning rate by iterations\n",
    "* When the cost function is very *irregular*, SGD can help the algorithm jump out of local minima, hence has a bettter chance of finding the global minimum than Batch GD.\n",
    "* *Simulated Annealing* starts with large learning rate and get smaller and smaller\n",
    "\n",
    "### Mini-batch Gradient Descent\n",
    "\n",
    "* Exercise 4. **Note** that unless you gradually reduce the learning rate, Stochastic GD and Mini-batch GD will never truly converge; instead they will keep jumping back and forth around the global optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves\n",
    "* [Bias-variance tradeoff](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized Linear Models\n",
    "\n",
    "### Ridge Regression\n",
    "* Ridge Regression cost function $J(\\theta) = MSE(\\theta) + \\alpha \\dfrac{1}{2} \\sum_{i}^{n}\\theta_i^2$\n",
    "* Closed-form solution $\\hat{\\theta} = (\\mathbf{X}^T\\cdot \\mathbf{X} + \\alpha \\mathbf{I})^{-1}\\cdot \\mathbf{X}^T \\cdot \\mathbf{y}$\n",
    "\n",
    "### Lasso Regression\n",
    "* Lasso cost function $J(\\theta) = MSE(\\theta) + \\alpha \\sum_{i}^{n}\\mid\\theta \\mid$\n",
    "* Lasso can be solved by Gradient Descent if we use subgradient vectors \n",
    "$g(\\theta, J)=\\bigtriangledown_\\theta MSE(\\theta) + [\\text{sign}{(\\theta_1)} ,...,  \\text{sign}{(\\theta_n)}]^T$, where \n",
    "\n",
    "$$\\text{sign}(\\theta_i)=\\left\\{\n",
    "                \\begin{array}{ll}\n",
    "                  -1, \\qquad \\text{if } \\theta_i<0\\\\\n",
    "                  0, \\qquad \\text{if } \\theta_i=0 \\\\\n",
    "                  +1, \\qquad \\text{if } \\theta_i>0\n",
    "                \\end{array}\n",
    "              \\right.$$\n",
    "\n",
    "### Elastic Net\n",
    "* Cost function $J(\\theta) = MSE(\\theta) + r \\alpha \\sum_{i}^{n}\\mid\\theta \\mid + \\dfrac{1-r}{2} \\alpha \\sum_{i}^{n}\\theta_i^2$\n",
    "\n",
    "### Early Stopping\n",
    "* Stop training when the validation error stops decreasing for a long period of iterations.\n",
    "\n",
    "### Model Comparison\n",
    "* **plain Linear Regression versus Ridge**: A model with some regularization typically performs better, so shouldgenerally prefer Ridge regression. Moreover, when using the normal equation, $\\mathbf{X}^T\\cdot \\mathbf{X}$ is not always invertable or stable, but $(\\mathbf{X}^T\\cdot \\mathbf{X} + \\alpha \\mathbf{I})$ is.\n",
    "* **Ridge versus Lasso**: If you need automatic feature selection, use Lasso\n",
    "* **Lasso versus ElasticNet**: Elastic Net is generally perferred since Lasso may behave erratically in some cases (strongly correlated features or more features than training instances). However it does add an extra hyperparameter to tune. Could use Elastic Net with `l1_ratio` close to 1 to get Lasso without the erratic behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "### Probability, Cost Function, Training\n",
    "Step-by-step derivation of LR, and gradient descent of LR\n",
    "* Estimated probability $\\hat{p} = h_\\theta(\\mathbf{x})=\\sigma(\\theta^T\\cdot \\mathbf{x})$ where $\\sigma(t)=\\dfrac{1}{1+\\exp(t)}$\n",
    "* Cost function for a single traning instance \n",
    "    $$c(\\theta) = \\left\\{\n",
    "                \\begin{array}{ll}\n",
    "                  -\\log (\\hat{p}) \\quad\\qquad \\text{if } y=1\\\\\n",
    "                  -\\log(1-\\hat{p}) \\qquad \\text{if } y=0\n",
    "                \\end{array}\n",
    "              \\right.$$\n",
    "              \n",
    "* LR cost function (negative log-likelihood): $J(\\theta) =  -\\frac{1}{m}\\sum_{i=1}^m [y^{(i)}\\log (\\hat{p}^{(i)}) + (1-y^{(i)})\\log (1-\\hat{p}^{(i)})] $. $J(\\theta)$ is **convex**, but has no closed-form solution. Could be solved using gradient descent, with $l1$ and/or $l2$ regularization.\n",
    "* To derive $J'(\\theta)$, notice that we have $\\frac{\\partial}{\\partial t}\\sigma = \\sigma(1-\\sigma)$, and $\\frac{\\partial}{\\partial h} \\log(h) = \\frac{1}{h}$. Then use chain rule and cancel out redundant terms, we've got\n",
    "    $$\\dfrac{\\partial}{\\partial \\theta_j}=\\dfrac{1}{m}\\sum_{i=1}^m(\\sigma(\\theta^T\\cdot \\mathbf{x}^{(i)})-y^{(i)})\\mathbf{x}^{(i)}$$\n",
    "    \n",
    "\n",
    "### Decision Boundary\n",
    "* LR has a *linear decision boundry* ($\\hat{p} == 0.5$). Because $\\sigma(t)$ is a monotonic function, so $\\sigma(\\theta^T\\cdot \\mathbf{x}) = 0.5$ is equivalent of $\\theta^T\\cdot \\mathbf{x} = 0$\n",
    "\n",
    "### Softmax Regression (Multinomial LR)\n",
    "Step-by-step derivation\n",
    "* Softmax score $s_k(\\mathbf{x}) = \\theta_k^T\\cdot \\mathbf{x}, \\quad k \\in 1,...,K$. **Note** that each class has its own dedicated parameter vector $\\theta_k$\n",
    "* Softmax function $\\hat{p}_k = \\sigma(\\mathbf{s}(\\mathbf{x}))_k = \\dfrac{\\exp(s_k(\\mathbf{x}))}{\\sum_{j=1}^K\\exp(s_j(\\mathbf{x}))}$\n",
    "* To make prediction $\\hat{y} = \\underset{k}{\\text{argmax}}(\\sigma(\\mathbf{s}(\\mathbf{x}))_k) = \\underset{k}{\\text{argmax}}(\\theta_k^T\\cdot \\mathbf{x}) $\n",
    "* Cost function (Cross Entropy) $J(\\Theta) = -\\frac{1}{m}\\sum_{i=1}^m \\sum_{k=1}^K [y_k^{(i)}\\log (\\hat{p}_k^{(i)})]$\n",
    "* Gradient vector for class $k$ is $\\bigtriangledown_{\\theta_k} J(\\Theta) = \\frac{1}{m}\\sum_{i=1}^m(\\hat{p}_k^{(i)}-y_k^{(i)})\\mathbf{x}^{(i)}$\n",
    "\n",
    "* Decision boundaries between any two classes are *linear*\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "* Detailed implementation [notebook](https://github.com/ageron/handson-ml/blob/master/04_training_linear_models.ipynb) by [Aur√©lien Geron](https://github.com/ageron)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
